##
# hostname for which the updater should capture the events for (filtering events based on meta.domain)
hostname: www.wikidata.org

##
# path to the generated checkpoints
checkpoint_dir: hdfs://analytics-hadoop/wmf/discovery/streaming_updater/checkpoints

##
# path to store "spurious" events, events that are inconsistent with the state of the application
spurious_events_dir: hdfs://analytics-hadoop/wmf/discovery/streaming_updater/spurious_events

##
# path to events considered "late" with the event reordering operation
late_events_dir: hdfs://analytics-hadoop/wmf/discovery/streaming_updater/late_events

##
# path to events we were unable to fetch the data for
failed_ops_dir: hdfs://analytics-hadoop/wmf/discovery/streaming_updater/failed_events

##
# kafka brokers used to consume and produce messages
brokers: kafka-jumbo1001.eqiad.wmnet:9092

##
# prefixes to append to all the input topic names, to support the WMF multi-DC layout of the kafka topics
topic_prefixes: eqiad.,codfw.

##
# input topics
rev_create_topic: mediawiki.revision-create
page_delete_topic: mediawiki.page-delete
suppressed_delete_topic: mediawiki.page-suppress
page_undelete_topic: mediawiki.page-undelete

##
# kafka consumer group, used to fetch the initial set of offset then only used for monitoring
consumer_group: wdqs_streaming_updater_test

##
# parallelism for the sources
# consumer_parallelism: 1

##
# window length (ms) for the reordering operation
# reordering_window_length: 60000

##
# enforce parallelism of the reordering operation (defaults to job parallelism)
reordering_parallelism: 1

##
# enforce parallelism of the decide mutation operation (large state) (defaults to job parallelism)
decide_mut_op_parallelism: 10

##
# enforce parallelism of the diff generation (async IO)
generate_diff_parallelism: 2

##
# timeout for the generate diff async IO (defaults to 5minute) -1 to disable
generate_diff_timeout: -1

##
# thead pool size for the generate diff async IO (defaults to 30)
wikibase_repo_thread_pool_size: 30

##
# output topic
output_topic: wdqs_streaming_updater_test

##
# output topic partition
output_topic_partition: 0

##
# idleness (ms) of input sources, default to 1minute
#
# - a value that is too low (< 1s) may incorrectly detect the stream as idle
# and might jump to higher watermarks issued from low rate streams and will end
# up marking as late events most events of this stream
#
# - a value that is too high (>?) may cause backfills to fail because too many
# events may be buffered in the window operation while idleness is reached.
# Later these events will likely be triggered at the same time causing too much
# backpressure and will cause the checkpoint to fail.
# (bug? some thread being blocked on
#  org.apache.flink.runtime.io.network.buffer.LocalBufferPool.requestMemorySegmentBlocking)
input_idleness: 2000

##
# max lateness (ms): allowed out-of-orderness
# max_lateness: 60000

##
# checkpoint_interval (ms)
checkpoint_interval: 30000

##
# checkpoint timeouts
checkpoint_timeout: 900000

##
# min pause (ms) between checkpoints, defaults to 2seconds
# min_pause_between_checkpoints: 2000

##
# watermark intervals (ms), defaults to 200millis
# auto_wm_interval: 200

##
# enable/disable exactly_once, defaults to true
# exactly_once: true

##
# enable flink latency tracking (defaults disabled), in millisec
# latency_tracking_interval: 1000

##
# tune network buffer timeout (ms)
# network_buffer_timeout: 100
